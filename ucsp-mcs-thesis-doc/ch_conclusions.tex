\chapter{Discussion and Conclusions}
\label{ch:conclusions}
The main objective of this work is to recover visual encodings from bitmap images of map visualizations. To achieve our goal, we analyze the map and legend regions using different approaches for each one; after these analyses, we obtain spatial and color information that is used to infer the visual encoding. However, our work has some limitations and possible improvements that are presented in \autoref{sec:limitations}. Finally, our conclusions are presented in \autoref{sec:conclusions}.

\section{Limitations and Future Work}
\label{sec:limitations}

\myparagraph{Color legend inside plotting area.}
As we explain in Section y, we are assuming our map visualizations have the color legend outside the plotting area. This is a common convention in geoscience publications. However, this is not always true in documents from other communities. For example, because of space constraints, authors may try to reduce chart sizes by embedding the legend in the plotting area. As an immediate future work, we plan to explore other techniques from computer vision and propose an algorithm supporting color legends inside the plotting area. Previous works had described some options to tackle this problem~\citep{Poco2017a, Siegel2016}; nevertheless, those methods are based on detecting textual information as an initial step, which may propagate more error than alternative vision-based solutions.


\myparagraph{Multiple geographic coordinates.}
There exist multiple standards for geographic coordinates. Our approach assumes that map visualizations contain latitudes and longitudes. However, during our research, we found that other coordinates systems exist such as the \emph{Universal Transverse Mercator (UTM)} and \emph{Military Grid Reference System}. Our technique does not support those systems because we did not find enough map images in the selected geoscience journals; however, we intend to explore new data sources and, if necessary, generalize our techniques to handle those cases. 


\myparagraph{Maps without coordinates.}
It is also common to render geographic maps without coordinates, \ie without textual information indicating latitude and longitude values. Analyzing our image corpus, we did not find many of these cases; however, we know that we can find many of them on the Internet. A possible solution would be to apply techniques from shape analysis and match the map boundaries with pre-built maps in order to identify spatial locations and map projection types. 


\myparagraph{Discrete legends.}
Another limitation of our work is the color legend types supported. As we described before, we only support continuous and quantized color legends. An immediate future work would be to extend our work to handle discrete color legends. A partial solution is presented in \citep{Poco2017a}; however, that method similarly does not work when the legend lies inside the plotting area. 


\myparagraph{Improving caption generation.}
We proposed a single approach for caption generation as a proof of concept, however, more sophisticated techniques can be used.
Techniques from \ac{NLP} might aid to generate captions with more variability and complexity.


\myparagraph{Automatic chart interpretation.}
The work presented in this thesis is part of a more ambitious objective. The goal is to create an automatic chart interpretation system that, given any chart image, can automatically infer the visual encoding and, as is feasible, extract the underlying data or approximate distributions thereof. If we accomplish this goal, we could create more impactful applications such as improving figure indexing and search, make chart images more accessible for people with disabilities, and perform large-scale analysis of visualization practices.


\section{Conclusions}
\label{sec:conclusions}

In this thesis, we present a novel approach to extract the visual encoding from map visualization images. Given a bitmap map image as input, we generate a visual encoding specification in a format similar to Vega-Lite. We trained and validated each component of our pipeline using real data collected from scientific documents, and our results show high accuracies on each task. Moreover, we developed iGeoMap, a web-based system to improve the map visualization understanding. iGeoMap has different modules which use the output of our pipeline: (1) recoloring to improve perceptual effectiveness, (2) interactive visualizations from a bitmap image, (3) generation of captions for geographic regions based on user's interaction, (4) reprojection to change the design of the map, and (5) recovery of encoded data from map visualizations. In addition, we have created a manually-annotated corpus of geographic map images that were used to evaluate our pipeline and can be used by the scientific community to find and solve new challenges.
